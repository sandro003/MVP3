{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Nfp838orH39X",
        "X2k2BKuspovX",
        "W___0k1Ettb7",
        "KTgVp1iLZ8fc"
      ],
      "authorship_tag": "ABX9TyPBY2zClRXOxIec0iTbNyp2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandro003/MVP3/blob/main/Machine_Learning_%26_Analytics_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##INTRODUÇÃO:\n",
        "Todo ser humano tem o direito à água potável que, além de fundamental para a sua saúde, é um direito humano básico e fundamental para políticas públicas eficazes. Estudos mostram que Investimentos em abastecimento de água e saneamento geram benefícios econômicos, pois as economias resultantes da redução dos impactos à saúde e dos custos médicos superam amplamente os gastos necessários para sua implementação.\n",
        "\n",
        "Com base acima entendi que seria viável treinar alguns modelos de machine learning para um problema de classificação passando por algumas etapas para poder avaliar e comparar os resultados com os modelos treinados.\n",
        "\n",
        "Os  modelos serão treinados usando um dataset de \"Água Potável\" e explorará algoritmos como Random Forest, Logistic Regression e KNN para identificar as características que indicam se a água é segura para consumo humano.\n"
      ],
      "metadata": {
        "id": "XP48rVVLnjas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparando o ambiente para a criação do MVP Machine Learning & Analytics e realizando a Análise dos Dados\n",
        "\n",
        "Nesta etapa a ideia é entender a informação que está disponível levando-se em conta algumas estatísticas descritivas para uma possível necessidade de transformação na etapa de preparação de dados. Abaixo foram dispostos alguns comandos bem como suas finalidades."
      ],
      "metadata": {
        "id": "Nfp838orH39X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ob9LK3eZA3Ee"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive #(Preparando o ambiente para criação do MVP Machine Learning & Analytics)\n",
        "drive.mount('/content/drive'),"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bibliotecas responsáveis por fazerem a leitura e impressão da base de dados\n",
        "import pandas as pd #(Importando PANDAS e criando alias para facilitar na digitação)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "import seaborn as sns  # Importa o Seaborn e define o alias 'sns'\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc"
      ],
      "metadata": {
        "id": "aFUqIXTaFTLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- Realizando a importação do arquivo csv e verificando as características gerais do Dataframe."
      ],
      "metadata": {
        "id": "VvIhbVhOFabN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lendo o arquivo csv\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/sandro003/MVP3/refs/heads/main/water_potability.csv')"
      ],
      "metadata": {
        "id": "DDQezrtXFbfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibindo as primeiras linhas do DataFrame (Mostra as 5 primeiras linhas por padrão e as 5 últimas)\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "EyVC0RtwFkGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizando as informações gerais do DataFrame (Informações sobre colunas, tipos de dados e valores nulos)\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "j0iTqdrRIF3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazendo um resumo estatístico das colunas numéricas (Estatísticas descritivas como média e desvio padrão)\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "y0mktP3QIVkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar a dimensão do DataFrame, ou seja, a quantidade de atributos e instâncias existentes (Número de linhas e colunas)\n",
        "print(f\"Dimensões do dataset: {df.shape}\")"
      ],
      "metadata": {
        "id": "-6PZ5iqsIh1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pré-processamento dos Dados\n",
        "Nesta etapa a ideia é identificar e tratar valores ausentes, separar recursos e rótulos, normalizar os dados, dividir os dados em treino e teste. Como Premissas e Hipóteses verifiquei que as variáveis de entrada estão relacionadas com o problema de forma que o modelo preditivo foi aplicado com sucesso e existiam padrões de comportamento que foram encontrados pelos algoritmos de machine learning. A preparação dos dados foi feita nesta etapa do MVP onde foi feita a limpeza, a transformação, a divisão, além da visualização e análise exploratória dos dados. Para poder selecionar os dados foram impostas Restrições de Qualidade pois utilizei somente dados completos (sem valores faltantes).\n",
        "\n"
      ],
      "metadata": {
        "id": "X2k2BKuspovX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar se há valores ausentes (Contagem de valores nulos por coluna)\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "WX8a_lizIoOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tratar valores ausentes (Removendo linhas com valores nulos \"NaN\")\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "GrmXCRVfRj8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar o dataset após o tratamento dos valores ausentes (Contagem de valores nulos por coluna)\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "bHrZh-I2tsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar X (features) e y (target) onde 'Potability' é o rótulo\n",
        "X = df.drop('Potability', axis=1)\n",
        "y = df['Potability']"
      ],
      "metadata": {
        "id": "T7ynJmHgRqOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar os dados (padronização)\n",
        "scaler = StandardScaler()"
      ],
      "metadata": {
        "id": "aBE7zzwvmDkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "fP_DjnvywTw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar histogramas para as features\n",
        "X.hist(figsize=(12, 10), bins=20, edgecolor='black')\n",
        "plt.suptitle('Distribuição das Variáveis (Features)', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mog4xBqOjJV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heatmap de correlação entre as variáveis\n",
        "plt.figure(figsize=(10, 8))\n",
        "correlation_matrix = X.corr()\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n",
        "plt.title('Mapa de Correlação entre Variáveis', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Oi3j-L42jVW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplots para cada variável em relação à classe Potability\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, column in enumerate(X.columns, 1):\n",
        "    plt.subplot(3, 3, i)\n",
        "    sns.boxplot(x=y, y=X[column])\n",
        "    plt.title(f'{column} vs Potability', fontsize=10)\n",
        "    plt.xlabel('Potability')\n",
        "    plt.ylabel(column)\n",
        "    plt.tight_layout()\n",
        "plt.suptitle('Distribuição de Variáveis por Classe', fontsize=16, y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6MytSnr-jdDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento e Avaliação dos Modelos de Classificação\n",
        "Nesta etapa a ideia foi abordar as questões relacionadas à modelagem e escolha de algoritmos para prever se a água é potável ou não. Resolvi testar com 3 algoritmos diferentes e apurar qual teria o melhor desempenho e aplicar o modelo. Foram treinados os modelos Random Forest, Logistic Regression e KNN nos dados de treino e avaliadas as performances usando acurácia, matriz de confusão e curvas ROC."
      ],
      "metadata": {
        "id": "W___0k1Ettb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir em X (features) e y (target)\n",
        "X = df.drop('Potability', axis=1)  # Features\n",
        "y = df['Potability']  # Target"
      ],
      "metadata": {
        "id": "UW4NACI9Ryco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar os dados (apenas X)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "49p-gSqHSTfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo usando Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições (Probabilidades para classe positiva)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_pred_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Avaliação\n",
        "print(\"Random Forest Classifier\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf.classes_)\n",
        "disp.plot(cmap=\"Blues\", values_format='d')\n",
        "plt.title(\"Matriz de Confusão - Random Forest\")\n",
        "plt.show()\n",
        "\n",
        "# Importância das Features\n",
        "feature_importances = rf.feature_importances_\n",
        "features = X.columns # Use the original DataFrame 'X' to get the column names\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=feature_importances, y=features, palette=\"viridis\")\n",
        "plt.title(\"Importância das Features - Random Forest\", fontsize=16)\n",
        "plt.xlabel(\"Importância\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_rf)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.title(\"Curva ROC - Random Forest\", fontsize=16)\n",
        "plt.xlabel(\"Taxa de Falsos Positivos\")\n",
        "plt.ylabel(\"Taxa de Verdadeiros Positivos\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7V4Uix5mhU3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo usando Logistic Regression\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições (Probabilidades para classe positiva)\n",
        "y_pred_log_reg = log_reg.predict(X_test)\n",
        "y_pred_proba_log_reg = log_reg.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Avaliação\n",
        "print(\"Logistic Regression\")\n",
        "print(classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_test, y_pred_log_reg)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=log_reg.classes_)\n",
        "disp.plot(cmap=\"Blues\", values_format='d')\n",
        "plt.title(\"Matriz de Confusão - Logistic Regression\")\n",
        "plt.show()\n",
        "\n",
        "# Coeficiente das Features para regressão logística\n",
        "coefficients = log_reg.coef_[0]\n",
        "features = X.columns  # Usando o DataFrame original 'X' para obter os nomes das colunas\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=coefficients, y=features, palette=\"viridis\")\n",
        "plt.title(\"Coeficientes das Features - Logistic Regression\", fontsize=16)\n",
        "plt.xlabel(\"Coeficiente\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_log_reg)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.title(\"Curva ROC - Logistic Regression\", fontsize=16)\n",
        "plt.xlabel(\"Taxa de Falsos Positivos\")\n",
        "plt.ylabel(\"Taxa de Verdadeiros Positivos\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X2r9S1z83QiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinar o modelo K-Nearest Neighbors (KNN)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Fazer predições\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "y_pred_proba_knn = knn.predict_proba(X_test)[:, 1]  # Probabilidades para a classe positiva\n",
        "\n",
        "# Avaliação\n",
        "print(\"K-Nearest Neighbors\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Matriz de Confusão\n",
        "cm = confusion_matrix(y_test, y_pred_knn)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn.classes_)\n",
        "disp.plot(cmap=\"Blues\", values_format='d')\n",
        "plt.title(\"Matriz de Confusão - K-Nearest Neighbors\")\n",
        "plt.show()\n",
        "\n",
        "# Curva ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_knn)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.title(\"Curva ROC - K-Nearest Neighbors\", fontsize=16)\n",
        "plt.xlabel(\"Taxa de Falsos Positivos\")\n",
        "plt.ylabel(\"Taxa de Verdadeiros Positivos\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Acurácia por número de vizinhos (k)\n",
        "k_values = range(1, 21)\n",
        "mean_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    score = knn.score(X_test, y_test)  # Usando o método .score para calcular a acurácia\n",
        "    mean_scores.append(score)\n",
        "\n",
        "# Plotar a acurácia por número de vizinhos\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_values, mean_scores, marker='o', linestyle='-', color='b')\n",
        "plt.title(\"Acurácia por Número de Vizinhos (k)\", fontsize=16)\n",
        "plt.xlabel(\"Número de Vizinhos (k)\")\n",
        "plt.ylabel(\"Acurácia\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Kf_c80i7iTWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Métricas de avaliação para cada modelo\n",
        "metrics = ['accuracy', 'precision', 'recall', 'f1-score']\n",
        "knn_report = classification_report(y_test, y_pred_knn, output_dict=True)\n",
        "# Use y_pred_log_reg instead of y_pred_lr\n",
        "lr_report = classification_report(y_test, y_pred_log_reg, output_dict=True)\n",
        "rf_report = classification_report(y_test, y_pred_rf, output_dict=True)\n",
        "\n",
        "# Preparando os dados para o gráfico\n",
        "metrics_data = {\n",
        "    'KNN': [knn_report['accuracy'], knn_report['1']['precision'], knn_report['1']['recall'], knn_report['1']['f1-score']],\n",
        "    'Logistic Regression': [lr_report['accuracy'], lr_report['1']['precision'], lr_report['1']['recall'], lr_report['1']['f1-score']],\n",
        "    'Random Forest': [rf_report['accuracy'], rf_report['1']['precision'], rf_report['1']['recall'], rf_report['1']['f1-score']],\n",
        "}\n",
        "\n",
        "# Gráfico de barras comparando as métricas de avaliação\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "metrics_df = pd.DataFrame(metrics_data, index=metrics)\n",
        "metrics_df.plot(kind='bar', ax=ax)\n",
        "ax.set_title('Comparação de Métricas de Avaliação entre Modelos')\n",
        "ax.set_ylabel('Valor')\n",
        "ax.set_xlabel('Métricas')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "N9OosaMyqZqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar os resultados\n",
        "# Configurar validação cruzada (se ainda não estiver configurada)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Escalar os dados\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Criar o melhor modelo KNN (substitua 5 pelo melhor k)\n",
        "knn_best = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Calcular as pontuações de validação cruzada\n",
        "scores_knn = cross_val_score(knn_best, X_scaled, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Criar e treinar o modelo de Regressão Logística\n",
        "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
        "scores_lr = cross_val_score(lr, X_scaled, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Criar e treinar o modelo Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "scores_rf = cross_val_score(rf, X_scaled, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Criar um dicionário para armazenar os resultados\n",
        "results = {\n",
        "    'KNN': scores_knn,\n",
        "    'Logistic Regression': scores_lr,\n",
        "    'Random Forest': scores_rf\n",
        "}\n",
        "\n",
        "# Verifique se todos os modelos têm o mesmo número de dobras\n",
        "assert len(scores_knn) == len(scores_lr) == len(scores_rf), \"O número de dobras nos modelos não é igual!\"\n",
        "\n",
        "# Visualizar os resultados\n",
        "plt.figure(figsize=(10, 6))\n",
        "for model_name, scores in results.items():\n",
        "    plt.plot(range(1, len(scores) + 1), scores, marker='o', linestyle='--', label=model_name)\n",
        "\n",
        "plt.title('Comparação de Modelos - Acurácia por Dobra')\n",
        "plt.xlabel('Dobra')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6zmHQI8qOd6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparar o Desempenho e Ajustar Hiperparâmetros\n",
        "Nesta etapa a ideia foi comparar o desempenho dos modelos acima e otimizar os hiperparâmetros para obter a melhor performance do modelo. Utilizei como métrica a acurácia e optei por usar o KNN como algoritmo principal. Testei algumas combinações de valores de hiperparâmetros em uma grade para encontrar a melhor combinação (Grid Search).\n"
      ],
      "metadata": {
        "id": "KTgVp1iLZ8fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testar diferentes valores de k\n",
        "k_values = range(1, 21)  # Valores de k de 1 a 20\n",
        "mean_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
        "    mean_scores.append(scores.mean())\n",
        "\n",
        "# Plotar os resultados\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_values, mean_scores, marker='o', linestyle='--', color='b')\n",
        "plt.title('Ajuste do Número de Vizinhos (k)')\n",
        "plt.xlabel('Número de Vizinhos (k)')\n",
        "plt.ylabel('Acurácia Média')\n",
        "plt.xticks(k_values)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8fXnZHpV1Gqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Treinando o modelo KNN com Cross-Validation e usando a validação cruzada para avaliar o desempenho. Avaliando e ajustando seus hiperparâmetros\n",
        "\n",
        "# Configurand validação cruzada\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Definindo a lista de valores de k para testar\n",
        "k_values = [3, 5, 7, 9, 11, 13]\n",
        "\n",
        "# Iterar sobre os valores de k e calcular a acurácia média para cada valor\n",
        "mean_scores = []\n",
        "for k in k_values:\n",
        "    # Criar um novo modelo KNN com o valor atual de k\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "    # Calcular a acurácia usando cross-validation\n",
        "    scores = cross_val_score(knn, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "    # Armazenar a acurácia média para o valor atual de k\n",
        "    mean_scores.append(scores.mean())\n",
        "\n",
        "# Imprimir os resultados\n",
        "for k, score in zip(k_values, mean_scores):\n",
        "    print(f\"Acurácia média para k={k}: {score:.4f}\")\n",
        "\n",
        "# Encontrar o melhor valor de k\n",
        "best_k = k_values[mean_scores.index(max(mean_scores))]\n",
        "print(f\"Melhor valor de k: {best_k}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8X61oe_qT81L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Treinamento Final com o Melhor k (Após encontrar o melhor valor de k, treinei o modelo novamente para avaliar o desempenho.)\n",
        "\n",
        "# Melhor KNN\n",
        "best_k = grid_knn.best_params_['n_neighbors'] # Get best_k from GridSearchCV results\n",
        "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
        "\n",
        "# Avaliando com validação cruzada (Cross-Validation)\n",
        "final_scores = cross_val_score(knn_best, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "print(f\"Melhor KNN - Acurácias por dobra: {final_scores}\")\n",
        "print(f\"Melhor KNN - Acurácia média: {final_scores.mean():.4f}\")\n",
        "\n",
        "# Plotando a acurácia por dobra\n",
        "plt.figure(figsize=(3, 9))\n",
        "sns.boxplot(data=final_scores, color='lightblue')\n",
        "plt.title(f'Acurácia por Dobra - KNN (k={best_k})', fontsize=16)\n",
        "plt.ylabel('Acurácia')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ZiT0fiwupCiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CONCLUSÃO\n",
        "A utilização de modelos de machine learning para classificar a potabilidade da água é uma abordagem promissora para melhorar a gestão e o acesso à água potável. Através da aplicação de algoritmos como Random Forest, Logistic Regression e KNN, foi possível identificar de forma eficiente as variáveis que influenciam a qualidade da água, contribuindo para a implementação de políticas públicas mais assertivas e eficazes. Assim, o uso de tecnologias como machine learning pode ser uma ferramenta poderosa para promover um futuro mais sustentável e seguro para as populações, alinhando desenvolvimento econômico e proteção à saúde. Além disso, a análise comparativa entre os modelos permitirá selecionar o mais adequado para prever a potabilidade da água, trazendo benefícios significativos para a saúde pública e para a redução de custos com tratamentos médicos relacionados à ingestão de água contaminada."
      ],
      "metadata": {
        "id": "TRLOHbLEZB9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BIBLIOGRAFIA:\n",
        "Water Quality. Kaggle, 2023. Disponível em: https://www.kaggle.com/datasets/adityakadiwal/water-potability. Acesso em: 05/11/2024.\n",
        "\n",
        "Engenharia de Dados: o que é, o que faz e um Guia completo. Alura, 2023. Disponível em: https://www.alura.com.br/artigos/engenharia-dados?srsltid=AfmBOorWZVr2iVRqWcdb_6UGxSMEo0bEje0oltL2ydb8COmuYBDUr43E. Acesso em: 07/11/2024.\n",
        "\n",
        "Introdução à Ciência de Dados - Introdução à Machine Learning: UNIVESP, 2021. Disponível em: https://www.youtube.com/watch?v=tKx8E8pW0P0. Acesso em: 16/11/2024.\n",
        "\n",
        "Introdução a Machine Learning | Curso do Kaggle: Mario Filho. Youtube, 2022. Disponível em: https://www.youtube.com/watch?v=s2drgo58G2c. Acesso em: 23/11/2024.\n",
        "\n",
        "Como criar um modelo de Machine Learning: Nerd dos Dados. Youtube, 2023. Disponível em: https://www.youtube.com/watch?v=b3nSrholF_8. Acesso em: 28/11/2024\n",
        "\n",
        "Seu primeiro Projeto em Machine Learning: Comunidade DS. Youtube, 2023. Disponível em: https://www.youtube.com/watch?v=0K2JlPC-NM8. Acesso em: 07/12/2024."
      ],
      "metadata": {
        "id": "ElkzGbTNY1iq"
      }
    }
  ]
}